{"project": "qiskit-machine-learning", "project_url": "https://qiskit.org/documentation/machine-learning/", "show_commit_url": "http://github.com/Qiskit/qiskit-machine-learning/commit/", "hash_length": 8, "revision_to_hash": {"239": "9a69a85150390da9fdf2ab4633674c315ad9012b", "240": "640442c5009dc775eabad1ef887e10c2763896ee", "241": "c62aa57fb7514068077c8ab214e6f404c97bbd98", "242": "c4897b5a096d3e12d2655628a13d7373e86de76d", "243": "0ed1127f537d208f3086950f798d6fd9483a8da2", "244": "38afc4569b2e09900e1181467f1dcd6e4f051e9d", "248": "ab3cacd9eba1e6e45a4043cc5c5cf3318f3e9256", "260": "a38e1e8bd044d6993361fad6741131531ab6ef4b", "267": "1950083a811db617172f9eecae1ee78dabdc16f2", "271": "c1b224e0414d8c01494d5c43df5ae7a3c30f5e71", "280": "64c5a8e2c23bee7e2b3608a6f9b3292c02c764a6", "336": "6ff456e3aff312dfa10e0b0348d0727a92fae286", "386": "83c3add93d7b40479139b37ff3b61acc7acd11dd", "401": "1673c5539587aaa4c15f116cea0e9703cda4214d", "423": "d41b975444f56b6c203ffdae74390442196b57cd", "443": "140ab993c9f80e513fea896d9d67459ed20d1b60", "466": "e7249f617fa82d7fb2c5787f35e7d0c073a9eb3c", "476": "c030e4c69691d40f212f9c37caea769fc2a1c344", "501": "c3b547cd0c3a6f3cdec713dc30b3a8672abba49c", "516": "17474be282b20b23ec853f442d524024c504b3c7", "559": "720cfc755b62650281cf0fb5c9a4306b69711d67", "575": "6451a76d97b6cc48eb80370a2cf24ec8a85c50c8", "578": "b540a71117e936b700c0df4da35240b0e510d679", "581": "2c94bc78dd3d5815350f5409d50e774c203e54e0", "592": "b789f90587728abab39f4a55564401fc8a9fb58d", "603": "c6ee17d77c48fae7b73dec4f5ad591e7474a1d26", "605": "c0210908494d4389750984f90e219924d27248e6", "609": "0fbaf6d107a6dbe8a436b1a13d0649f53f6e22f0", "612": "a7532ba0f50ffdc0424625064843be9610c1fd92", "616": "3a6a456bd0c78de570ddddd242c9f13ef9ac7abc", "619": "3ca740f43859667b4a566e80b326c89c21fd03cd", "621": "2040af8c851644a498ec2320e74e7f467ecf3e8f", "634": "1d2adf43c5948e22bb91f93a5657159a1e5ce29d", "641": "479f9f03d2b6c1fbab936b5d6bfaee6eaee465b0", "648": "eb2ac94635921a28c49c292a8438ab2f26c64fbb", "667": "ae02128fdf48b78883eeb2542a650b24622af433", "670": "7824bacf7c3288aa5ab8ca1f9d1ae7177a8e81ee", "677": "89bc4308bab42637b91aca8f353ac219d99f93d0", "680": "2710e5beab80d305c2bb19dc618074b226d28f9a", "685": "f83f8504165da80e57b350b13bd867e5c46b88d3", "691": "2342f8620e69f882168d8f856cd02f3ba283a417", "696": "6fa31ff9392ad58d3b27693ee11f29c1600cec85", "710": "aae3941214cd9667a53b643f229d11d0bff32c60", "726": "61e1e180db024be17c49b7aafcd15d114d51c3fc", "739": "7950e84fca286039d70f6f859660c33acfc5bebf", "746": "15bf10f203d820facff4bb229621b38290fd9341", "756": "cbef37ac94a2ce95dd643b1b96010c05598903ff", "758": "cd7e2a04ef64283e55584699ee9614d1e311c6bd", "760": "6c9a6fa7ab96d795807e3015585d383d7e93c6b4", "764": "076d41500b545811c156aac362f4ef0e2c8325d1", "774": "b1e6de33ca5542e814ba35f79782e28ff48760b7", "777": "528839f70fc9bedeea9da6047c929106ccc42a66", "783": "16d7a14dd1b881437cc050d276d5cc36f481322d", "796": "c115b45728fc554f12fb1c369680e616472e8287", "804": "41a16e63bccd5ed4f71e5daaa73916008a1436b6", "814": "767059aaf4b23dfaf535b42fa19b6d0083c76cef", "816": "e5c463d3d8ed1265c723c74446bf96b6d2c682b5", "821": "f873482ae0352eaee576b272a61cdf3afde7b7fc", "824": "14228f8814450d6ccbc5e959dad8351666eda054", "827": "257d76daa4ed83473e0e9cfd3e96bfa8f24c2c26", "836": "ec800bc8a58b32f3052ff399d54f19a74417fc7d", "857": "6a0581ad20ff43664b6ff666f5dee0051ab2b516", "870": "629cf4423cfa3c84dcd819837154b0c47458ebd7", "880": "a1f9e39fb6352ff025eb1d3a43ee371914cba0fa", "887": "0cc2f5714aeed88ed763bd609cdd8b3aec9e2f7d", "891": "25ac98bfca1c1b2f3daa477b89a92b552d7dcfe8", "898": "f01a1217d8bd4a81a0ead48a62bf0f272de2bb2b", "900": "cd712663f81b7c9974e226e03e39fcf4d4c96a36", "916": "6331a14ec25fa623f9aadec45ddddd70258be63f", "920": "5ffc4b6c2853a144799f1f2f2bd4d921f9db4f48", "923": "610e99bfe758b320571d08c655ae18d7b3543fc2", "928": "a1cee4bf81797d89104fa2db31fc0182ea12f887", "936": "07c416c5dc11f0d2a25d57006afad8d7f8b8dfe1", "939": "df5d9f84e256ea1fa0066b6fecc5675b56f719ec", "941": "3e07b42a2d80808c13e57b728b71c6f2ccbf8a23", "969": "88c2a2c8813957fbc5320ee502efbf4e3df25710", "985": "4a8f8dcc8aea3dc02cd0b035263af1cca035deae", "991": "67553c892787bbd79629e6434faab7b7015de905", "997": "2782de52f9edcce06621cd7445d57542db36eb7d", "1001": "03134848996cfa12a86b6da2235563e6b793a274", "1008": "faa43e7f978122baaf52c24b3bc474cd33bd5af7", "1022": "c1df4d545f74fd166ee973868013a66478c07a20", "1024": "b3a5bf757155499deb25993991d24e1e50060b18", "1031": "3aeea207091712a585509cf51a5794ca94a3b5dd", "1036": "fd6cf77bd6be0d715b1afe0c44e8409232e0e93d", "1039": "66d0c9282b639822e144fd567fa31c02bcf16387", "1058": "d11fc594bf8396bf349a86d35d2f80ae8c427a0d", "1062": "95a91fcffd2447645f78a004e0ea4e3b457d76c1", "1100": "d7a58414f28792af4cbd59b582b013018cc02752", "1104": "b542cc1fd022f05a82259d8b0763353ad93585d2", "1114": "d692da2365ac70387b38ee032b3451134dde61ef", "1137": "e5c3c8d50f2337f46a6a5d0dbad05a1e4807b97e", "1139": "362367834a0968b87d82f6e37020453d31aa26d0", "1149": "91c48df5b4266e6e5402bfd7273e615aa2e68ca9", "1168": "e787447b3e3716778ee6103aaa714dbd28ffbf0b", "1176": "96135a673edb3500889af2f9b872c459f6784c7a", "1182": "dac42022fb6cd992dd2df58f7219f379c6d2af7a", "1185": "df924c949b595aa79d4c5ac1aa92749112d80813", "1188": "8b13eed90177a92eff0d71159cc1f0f4aa9d0416", "1193": "e0f1ee82e210a7c8647b3c796061ea94b3c71bc5", "1200": "94c5785bee03f2c6ce8ff88abfd915a194c1fa97", "1218": "f9b71556fde57e669c741e2c7ad7b0c1b4737434", "1224": "165e38e41fabe86008ad243037b859af995552d1", "1233": "a47b0b91d50b87b0ad2191d48d8af9688d1e2db8", "1235": "2ea9b170eab81cbf07be0a425b0242519ceb5b4d", "1241": "00831061ca0206af42e131fcb9b605c4acd404fa", "1259": "c29d7227714d1c22658acd88dd31d3cbc6e0d645", "1270": "6438697633cb58fc5afddf0099f508419c848d93", "1306": "0a49359f3c6a241e6b40f5442a7f370b1131a439", "1314": "8a6e73beca8175e782d17d562f8e7b8642f7697a", "1321": "38dc1ffce94bb765b40a8adae4b71929d3ce0377", "1337": "dfaacf82cd8be4fa92670ec7c2d86b0c8ade9766", "1343": "2b8c2d3daa0292ee10f0052cc88b4f759c900275", "1347": "03312fb8d3add0cf6a7b7fe4221fd302c8dd131c", "1359": "ec3cbccca8f8c588d1ac523f4b12dc8c0bcef5b9", "1364": "f6e7b61bfd66979ca1d0191c8470d8a9564c9092", "1375": "0dcd2a2260abbb7eac545746a2cab558872b9168", "1384": "6b048a362930babf3efe67fa152e3aa5bd315351", "1388": "7faed0dd9bd4226c7dfa6c49a5f359b7719daaf5", "1393": "6133a471f7bee9fe858f3c0e8645c225a06d4170", "1404": "673140c0624ad928ec1b6da307e58221847c48da", "1421": "48064e93291e98c271ac5f6a34e84da9dd886042", "1429": "f2fe1dc1a9f16aa67e0f66b1e1bc5385e9988b36", "1436": "84cbbff19d9d01bfd4bac2bea74d669d2e46aad7", "1457": "a3712cbfc00112a79f3c2daf4a0503f88b5f083f", "1487": "223c4127cf8874afeb349eba86d6bca1f498d14f", "1512": "741d3760b35cb725c079f9d60066590aba824328", "1557": "3a90cbf1cbac8b835fe56e170650fb5f14a5dc8c", "1565": "10bdf59f1741334e8d1c093e6489ccd7c6422e64", "1568": "3cfecd6fd149920962e77dceaeaafcf233da9cf7", "1578": "21976765ed185eb1f331c022cba43e7179e80cda", "1585": "d766fa3804e84e2eb9c5ff65879853f949c5763a", "1640": "9c7e313395e358f1404d2bebad2fc0261e791b2a", "1667": "7f7bde7895eb28e7d6c367b5f856058acbd7f838", "1678": "d7ed53b604a89c1ecd221db5976c58017bd76029", "1694": "c25af748c17fb4d938db4a80ad1076fe4b0e5243", "1712": "1baf45cde9e7613c25ad6df831ef5795e479183d", "1761": "a8a17f4ab0d9817ff59bd9e85cce926ff88fd2ea", "1791": "5d11c72f5838fe3836e4f8ed649a6c7b557f6679", "1794": "de370a614bdebc825eae8b47a107545d0a7ad71d", "1812": "c27715a41283fcb154ea3629e9e56bf729474270", "1827": "67376430c528e24265584aed4a7ec7f07229e155", "1832": "13725aebde394960cf65d88deafeaa538d811b6a", "1837": "7f677c0ef829351bf292a2db0a3e520cb57e8d2d", "1849": "d12d29fbc5a4417dd6bd1f6e670bcc8eef69adf3", "1865": "65afbb0d60bacc52df8753ebe3fc4e211dfd3733", "1877": "1f01764186ad5e6fd4b88deb4dfec1e5cbb05d03", "1881": "26bf303b4a7897ac3f0934d630d236660afa4b98", "1903": "aeed2df8798d2176547f0bb55648765aedabe380", "1919": "b01e6fa8f624837c68ffb577bb53c9db20f1df65", "1922": "0385b8ae6155c43a79bdf19f1a0a6d7828f60be7", "1925": "46535ea4584654b2040760753aa34abaa9e0d382", "1927": "54f6bd3cc6b28fa4c06a5c87984192bc2d0f0628", "1932": "4c6dffffdd099630f04cad3a87a3c0a7df1e9dd7", "1936": "bf9077e7788a38a2099273e499c61e192a9cb3e2", "1942": "8a1abfba48548b859d01737a7492baae83895b5b", "1949": "0a18aceda909bb8d414319fdfe0d35e1fe30f410", "1957": "865e1878d0206f7fd5dcbccfe228181b97cc1cab", "1961": "4181dcbfccbd64bf47a9d922987822cf4e90ab8b", "1967": "3dd9ee17ae34c776bc60ac846e924d0e138c2664", "1970": "585b795caab3e080902e0741e374eb2759fca777", "1975": "7382584428bda6ccbb0b0672284ac09abbfe587d", "2014": "26a5a69580d4f05cb4f0aa1525fc2144fa4413fa", "2020": "02e5f7ca4ab4de66fd271a863714b84cf4668bc2", "2037": "44bfc66a8aef1baf6794ab43ea9c73e5be34ce8e", "2048": "5a02c7639db6a86beb9a944b14721935a48932e6", "2071": "b542f47ccac25a5121ba65da59b88cf0e63d51fd", "2079": "dcbd78cb46301690e0e5555f6fe48fbc76f1a9b3", "2085": "e927a4850d2b4ae83441343c56cbd544d1555cff", "2087": "26c7a9e968826ee97ef429b0b2c02ddc22d841f9", "2093": "53c476287ab7caa745ece83cfaafacfa4122e844", "2097": "0c5cc73aedb974800964010d8226600d61b5f712", "2100": "820aaca9a69c0454eb598111a0a5f5f30e811dc9", "2111": "6f4d61336ecfca52d7621a77a5e3b5f07f8a1b34", "2118": "138cc5c59054a73bebe88a6c47e0dfb7a2e1dca5", "2124": "6e0f65fb72e1a677e100445e10108c51c52b0b72", "2145": "89ac02bd8004c24890cb00048c05e2956376fbc5", "2148": "80a591fde0c590e338596d157f9e8e0d65ec45b1", "2155": "1a00a69d46b466dc2ae04538a5e01aef3b2a16c5", "2162": "ac3c5471dfde5c6d8c4a5c3886d4b336bbc7a6f1", "2178": "2edc1f106c72a41ae2e99b58ee1edb85aa97d8bf", "2185": "a56158452e32354dfbc1f4835a0b362446af4eba", "2191": "70f70222b1c4523a6a7de3ff2b795e80c91ac9d5", "2193": "291b879f8884c769d11613c9c5adcebd7e9df7ae", "2200": "e157aa34234fec15649dc818ab97796d1e7dc5a5", "2206": "1ac7789c1ea716d785b0fddd3aeb7d85d414e3d6", "2208": "824e99341a45ea45766735207e39e010e0df2fd1", "2215": "ba12360b13bb946a7b1186dc19d5fb871152c334", "2232": "7d56f8d4e817ad1d716829c0a9f3cbb8e2dcd9a1", "2270": "a5f1d463a828d7f3b677a29e02cb04c438e6e122", "2281": "3d954de916be8f7d4854f3c4369281112f9b0fdb", "2287": "15f4c7ceedee0e876cd984c8737cc6e330b0aebc", "2303": "fd8e4e0933d33d88a833091b7cb187246ca8d792", "2364": "c81306a30435cdc5ab511552aba85b569f17d2a5", "2367": "3fbac5d3ba64afcad8b35a021fb4e8e647fd07e1", "2425": "5b075333d4a32b70888b398ee097b4388100af96", "2428": "16c08c9923a698bfb62b2352307ded506f10790c", "2447": "e971f8e2de14c69751b21ec83818303f463a395d", "2456": "6a7c8c0f56b9bef6a3e12dbda5dfc5fffcccefa4", "2464": "2085a84e3f7e794334e4a710510d3ef4542e53c2", "2472": "15155ceca27739b76490c3f4ab439b6ca5998e8f", "2481": "6ff781ef5852b01383ac20b9dd3dc765191ecd1b", "2493": "d35dea18d3595f5e402a9d4aa97a0ada9c94cefb", "2495": "d7e38b7fdff3de838f224580dc4aa8467e689e19", "2500": "63ecb3184216f56103f1e76d8facef792810a62f", "2504": "feb086a8f12b838dfd573fa65a0b01b5ce271b47", "2528": "005c9dc0cfb3068850fb33a709faa4bbd30b7c80", "2545": "5df0a738d1120c492ce7fb5e18d61ee8489a6b78", "2550": "3c71458067b885e5d0fb68f8f0526a32a9e3369f", "2554": "706b0a72c17d197943af40fa6d310f7b0ec75348", "2556": "753ff71b645b93dca80753dbaff3cb6491fd072c", "2568": "e9978f56cf978c5d4a19b1941e584f91586f804a", "2583": "3bf98b67618885bd09f4abbff7e381537a646fac", "2597": "11d6bdf802693ae4345896d086588aa1900b4134", "2603": "aad819a04228e16cc57b44f7b49f0112c72acde0", "2605": "242fbf57bb30da918b61989feb9383a4b4787def", "2608": "3c08f227e75517dc73f7349159f1faf375630d65", "2622": "3e1ed39e3f4d9b650db181866b6d12865a496613", "2631": "6850493212d11bb70218de6a69a9b93f59d44632", "2637": "f4d7ab09f2685871e24cf9bbd98619210c0d5dfd", "2642": "a8dfe68acfdcde9f12062ba646654e1e0468018d", "2658": "fb307ee4ddf9ad68087caa0bb45d70abbd2b3b5d", "2667": "505495fc219e7fc6466d66036a447591e488d93a", "2681": "7ff10b2ffbaa0e6a3a44d3f2061c9e3bdea29102", "2685": "7a5414bdcedfb10e8d6a9b33a08240d6ea318148", "2689": "cc11406614ccb829b8828444a4a6d0116ffc1f89", "2695": "b089cf6cfafbd6a965a62f84701f2b44c65a122a", "2734": "b2a167a0e173536f75117d45d9791dc7d652dd5d", "2763": "d2208ddd7e4a0286c05fb32023915f654cb15ac8", "2773": "f1ace88bd1745fbd7ff5be1466befcbc83c13ce3", "2783": "a678d69d2bbfb2979080e2fc7900dcaa9c4f363f", "2823": "75a6d2ba56e99742b18435a16d7bb2b9bb976e9d", "2832": "b0e8bfc009e7fccb06ba503f38c514b0b086495a", "2856": "1261ef19ee93e63328563155802653ef3699bc63", "2876": "149a2ef1304c9ed2dbc6df0d4a32277290e2a38e", "2884": "a1533ebc4d4cab2c43b5d017077df57369b1e3dc"}, "revision_to_date": {"239": 1614438631000, "240": 1614458421000, "241": 1614463594000, "242": 1614465534000, "243": 1614466179000, "244": 1614468757000, "248": 1615308773000, "260": 1615438445000, "267": 1615498334000, "271": 1615645840000, "280": 1615817263000, "336": 1616079505000, "386": 1616167682000, "401": 1616250531000, "423": 1616332802000, "443": 1616508903000, "466": 1616596410000, "476": 1616622395000, "501": 1616706390000, "516": 1617002437000, "559": 1617125381000, "575": 1617142024000, "578": 1617170825000, "581": 1617190749000, "592": 1617218365000, "603": 1617239805000, "605": 1617245011000, "609": 1617255124000, "612": 1617257877000, "616": 1617272920000, "619": 1617318053000, "621": 1617389398000, "634": 1617795004000, "641": 1617992966000, "648": 1618248966000, "667": 1618496056000, "670": 1618502846000, "677": 1618845355000, "680": 1618863207000, "685": 1619026161000, "691": 1619041515000, "696": 1619361500000, "710": 1619459416000, "726": 1619540790000, "739": 1619551851000, "746": 1619825359000, "756": 1620233618000, "758": 1620236736000, "760": 1620244018000, "764": 1620324520000, "774": 1620412579000, "777": 1620414870000, "783": 1620658042000, "796": 1620749410000, "804": 1620822837000, "814": 1620898589000, "816": 1620979220000, "821": 1621449347000, "824": 1621528402000, "827": 1621962549000, "836": 1622125124000, "857": 1622570496000, "870": 1622640515000, "880": 1622671081000, "887": 1622734668000, "891": 1622737756000, "898": 1622802452000, "900": 1622823595000, "916": 1623367044000, "920": 1623403061000, "923": 1623667458000, "928": 1623835729000, "936": 1623859757000, "939": 1623881228000, "941": 1624053289000, "969": 1624536046000, "985": 1624639326000, "991": 1624650227000, "997": 1624656793000, "1001": 1624795543000, "1008": 1624922165000, "1022": 1624997445000, "1024": 1624999325000, "1031": 1625006101000, "1036": 1625064653000, "1039": 1625076362000, "1058": 1625327651000, "1062": 1625409054000, "1100": 1625668932000, "1104": 1625676155000, "1114": 1625779366000, "1137": 1626124407000, "1139": 1626132122000, "1149": 1626180087000, "1168": 1626255029000, "1176": 1626270834000, "1182": 1626280490000, "1185": 1626285357000, "1188": 1626297558000, "1193": 1626333460000, "1200": 1626370357000, "1218": 1626705556000, "1224": 1626836530000, "1233": 1626955826000, "1235": 1626969817000, "1241": 1627531696000, "1259": 1628002802000, "1270": 1628023263000, "1306": 1628685956000, "1314": 1628801243000, "1321": 1629395347000, "1337": 1629730350000, "1343": 1629749095000, "1347": 1629757718000, "1359": 1629808246000, "1364": 1629983907000, "1375": 1630277777000, "1384": 1630434898000, "1388": 1630572329000, "1393": 1631051226000, "1404": 1631546275000, "1421": 1631698008000, "1429": 1631734292000, "1436": 1631902228000, "1457": 1632297330000, "1487": 1632409954000, "1512": 1632940607000, "1557": 1633428397000, "1565": 1633538524000, "1568": 1633542652000, "1578": 1633692340000, "1585": 1633972914000, "1640": 1634329156000, "1667": 1634730219000, "1678": 1635276058000, "1694": 1635536604000, "1712": 1635879753000, "1761": 1637077155000, "1791": 1637771920000, "1794": 1637924432000, "1812": 1638405940000, "1827": 1638556232000, "1832": 1638559443000, "1837": 1638565043000, "1849": 1638837787000, "1865": 1638911037000, "1877": 1639148538000, "1881": 1639157671000, "1903": 1639511326000, "1919": 1639575343000, "1922": 1639585424000, "1925": 1639589747000, "1927": 1639596626000, "1932": 1640033400000, "1936": 1641497496000, "1942": 1642007846000, "1949": 1642025077000, "1957": 1642696592000, "1961": 1642772458000, "1967": 1643048321000, "1970": 1643216916000, "1975": 1643385193000, "2014": 1644442752000, "2020": 1644501553000, "2037": 1644579113000, "2048": 1644624438000, "2071": 1645051122000, "2079": 1645129697000, "2085": 1645139709000, "2087": 1645183606000, "2093": 1645465183000, "2097": 1645526358000, "2100": 1645609324000, "2111": 1646153746000, "2118": 1646254819000, "2124": 1646353063000, "2145": 1646857934000, "2148": 1646862814000, "2155": 1646939976000, "2162": 1647016378000, "2178": 1647896758000, "2185": 1647972369000, "2191": 1648141100000, "2193": 1648150730000, "2200": 1648244517000, "2206": 1648499459000, "2208": 1648578295000, "2215": 1648745455000, "2232": 1648815297000, "2270": 1649195830000, "2281": 1649318293000, "2287": 1649364454000, "2303": 1649432281000, "2364": 1649752644000, "2367": 1649757406000, "2425": 1650031210000, "2428": 1650037369000, "2447": 1650459422000, "2456": 1650571209000, "2464": 1650615664000, "2472": 1650636092000, "2481": 1650896705000, "2493": 1651046993000, "2495": 1651052476000, "2500": 1651248798000, "2504": 1651255583000, "2528": 1651703729000, "2545": 1652217137000, "2550": 1652455296000, "2554": 1652470784000, "2556": 1652897001000, "2568": 1652998758000, "2583": 1653571073000, "2597": 1653929472000, "2603": 1654114939000, "2605": 1654156396000, "2608": 1654700834000, "2622": 1654893940000, "2631": 1655330950000, "2637": 1655489156000, "2642": 1655498281000, "2658": 1655787486000, "2667": 1656072277000, "2681": 1656450870000, "2685": 1656460337000, "2689": 1656512460000, "2695": 1656544420000, "2734": 1657317805000, "2763": 1657717634000, "2773": 1657793413000, "2783": 1657892509000, "2823": 1658392035000, "2832": 1658484361000, "2856": 1659287350000, "2876": 1659948307000, "2884": 1660097804000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz"], "machine": ["cd optimiation"], "num_cpu": ["12"], "os": ["Linux 5.8.0-55-generic"], "ram": ["65698320"], "python": ["3.8"], "sparse": [""], "torch": [""], "branch": ["main"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz", "machine": "cd optimiation", "num_cpu": "12", "os": "Linux 5.8.0-55-generic", "ram": "65698320", "python": "3.8", "torch": "", "sparse": "", "branch": "main"}], "benchmarks": {"circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_predict_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def time_predict_circuit_qnn_classifier(self, _, __):\n        \"\"\"Time predicting with CircuitQNN classifier.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_predict_circuit_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def time_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Time scoring CircuitQNN classifier on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_score_circuit_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_accuracy_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_accuracy_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the overall accuracy of the classification results.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_accuracy_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_f1_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_f1_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the f1 score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return f1_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_f1_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_precision_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_precision_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the precision score.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return precision_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_precision_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_recall_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_recall_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the recall score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return recall_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_recall_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_fit_benchmark.CircuitQnnFitClassifierBenchmarks.time_fit_circuit_qnn_classifier": {"code": "class CircuitQnnFitClassifierBenchmarks:\n    def time_fit_circuit_qnn_classifier(self, _, __, ___):\n        \"\"\"Time fitting CircuitQNN classifier to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str, optimizer: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "circuit_qnn_classifier_fit_benchmark.CircuitQnnFitClassifierBenchmarks.time_fit_circuit_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name", "optimizer"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_predict_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def time_predict_opflow_qnn_classifier(self, _, __):\n        \"\"\"Time predicting with classifier OpflowQNN.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_predict_opflow_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def time_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Time scoring OpflowQNN classifier on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_score_opflow_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_accuracy_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_accuracy_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the overall accuracy of the classification results.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_accuracy_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_f1_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_f1_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the f1 score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return f1_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_f1_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_precision_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_precision_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the precision score.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return precision_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_precision_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_recall_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_recall_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the recall score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return recall_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_recall_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_fit_benchmark.OpflowQnnFitClassifierBenchmarks.time_fit_opflow_qnn_classifier": {"code": "class OpflowQnnFitClassifierBenchmarks:\n    def time_fit_opflow_qnn_classifier(self, _, __, ___):\n        \"\"\"Time fitting OpflowQNN classifier to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str, optimizer: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "opflow_qnn_classifier_fit_benchmark.OpflowQnnFitClassifierBenchmarks.time_fit_opflow_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name", "optimizer"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_predict_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def time_predict_opflow_qnn_regressor(self, _, __):\n        \"\"\"Time predicting with OpflowQNN regressor.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_predict_opflow_qnn_regressor", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "1", "warmup_time": -1}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_score_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def time_score_opflow_qnn_regressor(self, _, __):\n        \"\"\"Time scoring OpflowQNN regressor on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_score_opflow_qnn_regressor", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "1", "warmup_time": -1}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mae_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def track_mae_opflow_qnn_regressor(self, _, __):\n        \"\"\"Mean absolute error of the model on data.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        mae = mean_absolute_error(y_true=self.test_labels, y_pred=predicts)\n        return mae\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mae_opflow_qnn_regressor", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1"}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mse_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def track_mse_opflow_qnn_regressor(self, _, __):\n        \"\"\"Mean squared error of the model on data.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        mse = mean_squared_error(y_true=self.test_labels, y_pred=predicts)\n        return mse\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mse_opflow_qnn_regressor", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1"}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_score_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def track_score_opflow_qnn_regressor(self, _, __):\n        \"\"\"R2 score of the model on data.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_score_opflow_qnn_regressor", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1"}, "opflow_qnn_regressor_fit_benchmark.OpflowQnnFitRegressorBenchmarks.time_fit_opflow_qnn_regressor": {"code": "class OpflowQnnFitRegressorBenchmarks:\n    def time_fit_opflow_qnn_regressor(self, _, __, ___):\n        \"\"\"Time fitting OpflowQNN regressor to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str, optimizer: str):\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(\n                quantum_instance_name, self.optimizers[optimizer]\n            )\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name, self.optimizers[optimizer])\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "opflow_qnn_regressor_fit_benchmark.OpflowQnnFitRegressorBenchmarks.time_fit_opflow_qnn_regressor", "number": 0, "param_names": ["dataset", "backend name", "optimizer"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "1", "warmup_time": -1}, "vqc_benchmark.VqcBenchmarks.time_predict_vqc_classifier": {"code": "class VqcBenchmarks:\n    def time_predict_vqc_classifier(self, _, __):\n        \"\"\"Time predicting with VQC.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "vqc_benchmark.VqcBenchmarks.time_predict_vqc_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "vqc_benchmark.VqcBenchmarks.time_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def time_score_vqc_classifier(self, _, __):\n        \"\"\"Time scoring VQC on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "vqc_benchmark.VqcBenchmarks.time_score_vqc_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "vqc_benchmark.VqcBenchmarks.track_accuracy_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_accuracy_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the overall accuracy of the classification results.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_accuracy_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_benchmark.VqcBenchmarks.track_f1_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_f1_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the f1 score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return f1_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_f1_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_benchmark.VqcBenchmarks.track_precision_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_precision_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the precision score.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return precision_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_precision_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_benchmark.VqcBenchmarks.track_recall_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_recall_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the recall score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return recall_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_recall_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_fit_benchmark.VqcFitBenchmarks.time_fit_vqc": {"code": "class VqcFitBenchmarks:\n    def time_fit_vqc(self, _, __, ___, ____):\n        \"\"\"Time fitting VQC to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(\n        self, dataset: str, quantum_instance_name: str, optimizer: str, loss_function: str\n    ) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n                loss_function=loss_function,\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n                loss_function=loss_function,\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "vqc_fit_benchmark.VqcFitBenchmarks.time_fit_vqc", "number": 0, "param_names": ["dataset", "backend name", "optimizer", "loss function"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"], ["'cross_entropy'", "'squared_error'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}}, "machines": {"cd optimiation": {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz", "machine": "cd optimiation", "num_cpu": "12", "os": "Linux 5.8.0-55-generic", "ram": "65698320", "version": 1}}, "tags": {"0.1.0": 616, "0.2.0": 1137, "0.2.1": 1359, "0.3.0": 1922, "0.3.1": 2085, "0.4.0": 2500}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}