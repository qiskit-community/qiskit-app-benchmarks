{"project": "qiskit-machine-learning", "project_url": "https://qiskit.org/documentation/machine-learning/", "show_commit_url": "http://github.com/Qiskit/qiskit-machine-learning/commit/", "hash_length": 8, "revision_to_hash": {"616": "3a6a456bd0c78de570ddddd242c9f13ef9ac7abc", "1136": "e5c3c8d50f2337f46a6a5d0dbad05a1e4807b97e", "1358": "ec3cbccca8f8c588d1ac523f4b12dc8c0bcef5b9", "1887": "0385b8ae6155c43a79bdf19f1a0a6d7828f60be7", "2038": "e927a4850d2b4ae83441343c56cbd544d1555cff", "2419": "63ecb3184216f56103f1e76d8facef792810a62f", "3007": "aae0bd472b72783bdd691a51e84aef89a6fb281c", "3032": "3702b74b8c515cdcdf82c5aa81036b652d28a0f7", "3044": "66e0476e9061751d0271df879d7c83a0f05a479f", "3053": "8f76b5ea28040b35acae320306c226519ea2566c", "3065": "6bd0be33cc96e9e4779f2c8ff7257c5ddc8e65d3", "3154": "c8d6eb271cc2a7e869a9200d663aa258de8fb2d4", "3170": "a53abb2b02162d9407849d9be3ff55db57d6b544", "3208": "2629e70c75f59bb7315cdd012dc8ed65898ffaf9", "3243": "670bc12ac7b696acdf4b1ea3e9f4242953a8555d", "3274": "ea94895f607065b2eb24a087c710dfa332debc24", "3283": "941bbea133eaf629f34c7406376e55b78f52821a", "3288": "f354fd502e51321162268bf25a92f698a0c25f79", "3301": "40f99bbe0bd055057ee0939034ec6f18d78f260f", "3306": "af319b7c04ab5e2330ab9e95543cc2e9b24d8ed6", "3311": "3c22367c822796691fe565786583e3b9e199da08", "3330": "c6f4216c6b336aa686e50c28d797257c3e664618", "3334": "85c028c15cc3de7cbf4afb4a3ce6af78d30b7acc", "3337": "892a672a6a6df0801d8176f95a7baa8ffe489498", "3345": "20e0f1bb9a6782728e1613cd0099fc07a5a628db", "3354": "a9ec4a60c038c3513e1fed34f7a30e52272b9a3b"}, "revision_to_date": {"616": 1617272920000, "1136": 1626124407000, "1358": 1629808246000, "1887": 1639585424000, "2038": 1645139709000, "2419": 1651248798000, "3007": 1665500939000, "3032": 1665673993000, "3044": 1665746131000, "3053": 1666003402000, "3065": 1666016466000, "3154": 1666293828000, "3170": 1666629576000, "3208": 1666903793000, "3243": 1667260125000, "3274": 1667394336000, "3283": 1667424822000, "3288": 1667505476000, "3301": 1667570690000, "3306": 1667584727000, "3311": 1667595850000, "3330": 1667939839000, "3334": 1667947182000, "3337": 1667995079000, "3345": 1668089791000, "3354": 1668177108000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz"], "machine": ["cd optimiation"], "num_cpu": ["12"], "os": ["Linux 5.8.0-55-generic"], "ram": ["65698320"], "python": ["3.8"], "torch": [""], "sparse": [""], "branch": ["main"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz", "machine": "cd optimiation", "num_cpu": "12", "os": "Linux 5.8.0-55-generic", "ram": "65698320", "python": "3.8", "torch": "", "sparse": "", "branch": "main"}], "benchmarks": {"circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_predict_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def time_predict_circuit_qnn_classifier(self, _, __):\n        \"\"\"Time predicting with CircuitQNN classifier.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_predict_circuit_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def time_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Time scoring CircuitQNN classifier on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_score_circuit_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_accuracy_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_accuracy_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the overall accuracy of the classification results.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_accuracy_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_f1_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_f1_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the f1 score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return f1_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_f1_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_precision_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_precision_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the precision score.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return precision_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_precision_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_recall_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_recall_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the recall score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return recall_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_recall_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_fit_benchmark.CircuitQnnFitClassifierBenchmarks.time_fit_circuit_qnn_classifier": {"code": "class CircuitQnnFitClassifierBenchmarks:\n    def time_fit_circuit_qnn_classifier(self, _, __, ___):\n        \"\"\"Time fitting CircuitQNN classifier to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str, optimizer: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "circuit_qnn_classifier_fit_benchmark.CircuitQnnFitClassifierBenchmarks.time_fit_circuit_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name", "optimizer"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_predict_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def time_predict_opflow_qnn_classifier(self, _, __):\n        \"\"\"Time predicting with classifier OpflowQNN.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_predict_opflow_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def time_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Time scoring OpflowQNN classifier on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_score_opflow_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_accuracy_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_accuracy_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the overall accuracy of the classification results.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_accuracy_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_f1_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_f1_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the f1 score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return f1_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_f1_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_precision_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_precision_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the precision score.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return precision_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_precision_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_recall_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_recall_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the recall score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return recall_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_recall_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_fit_benchmark.OpflowQnnFitClassifierBenchmarks.time_fit_opflow_qnn_classifier": {"code": "class OpflowQnnFitClassifierBenchmarks:\n    def time_fit_opflow_qnn_classifier(self, _, __, ___):\n        \"\"\"Time fitting OpflowQNN classifier to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str, optimizer: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "opflow_qnn_classifier_fit_benchmark.OpflowQnnFitClassifierBenchmarks.time_fit_opflow_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name", "optimizer"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_predict_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def time_predict_opflow_qnn_regressor(self, _, __):\n        \"\"\"Time predicting with OpflowQNN regressor.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_predict_opflow_qnn_regressor", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "1", "warmup_time": -1}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_score_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def time_score_opflow_qnn_regressor(self, _, __):\n        \"\"\"Time scoring OpflowQNN regressor on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_score_opflow_qnn_regressor", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "1", "warmup_time": -1}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mae_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def track_mae_opflow_qnn_regressor(self, _, __):\n        \"\"\"Mean absolute error of the model on data.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        mae = mean_absolute_error(y_true=self.test_labels, y_pred=predicts)\n        return mae\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mae_opflow_qnn_regressor", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1"}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mse_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def track_mse_opflow_qnn_regressor(self, _, __):\n        \"\"\"Mean squared error of the model on data.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        mse = mean_squared_error(y_true=self.test_labels, y_pred=predicts)\n        return mse\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mse_opflow_qnn_regressor", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1"}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_score_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def track_score_opflow_qnn_regressor(self, _, __):\n        \"\"\"R2 score of the model on data.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_score_opflow_qnn_regressor", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1"}, "opflow_qnn_regressor_fit_benchmark.OpflowQnnFitRegressorBenchmarks.time_fit_opflow_qnn_regressor": {"code": "class OpflowQnnFitRegressorBenchmarks:\n    def time_fit_opflow_qnn_regressor(self, _, __, ___):\n        \"\"\"Time fitting OpflowQNN regressor to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str, optimizer: str):\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(\n                quantum_instance_name, self.optimizers[optimizer]\n            )\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name, self.optimizers[optimizer])\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "opflow_qnn_regressor_fit_benchmark.OpflowQnnFitRegressorBenchmarks.time_fit_opflow_qnn_regressor", "number": 0, "param_names": ["dataset", "backend name", "optimizer"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "1", "warmup_time": -1}, "vqc_benchmark.VqcBenchmarks.time_predict_vqc_classifier": {"code": "class VqcBenchmarks:\n    def time_predict_vqc_classifier(self, _, __):\n        \"\"\"Time predicting with VQC.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "vqc_benchmark.VqcBenchmarks.time_predict_vqc_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "vqc_benchmark.VqcBenchmarks.time_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def time_score_vqc_classifier(self, _, __):\n        \"\"\"Time scoring VQC on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "vqc_benchmark.VqcBenchmarks.time_score_vqc_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "vqc_benchmark.VqcBenchmarks.track_accuracy_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_accuracy_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the overall accuracy of the classification results.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_accuracy_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_benchmark.VqcBenchmarks.track_f1_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_f1_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the f1 score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return f1_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_f1_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_benchmark.VqcBenchmarks.track_precision_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_precision_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the precision score.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return precision_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_precision_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_benchmark.VqcBenchmarks.track_recall_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_recall_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the recall score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return recall_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_recall_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_fit_benchmark.VqcFitBenchmarks.time_fit_vqc": {"code": "class VqcFitBenchmarks:\n    def time_fit_vqc(self, _, __, ___, ____):\n        \"\"\"Time fitting VQC to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(\n        self, dataset: str, quantum_instance_name: str, optimizer: str, loss_function: str\n    ) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n                loss_function=loss_function,\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n                loss_function=loss_function,\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "vqc_fit_benchmark.VqcFitBenchmarks.time_fit_vqc", "number": 0, "param_names": ["dataset", "backend name", "optimizer", "loss function"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"], ["'cross_entropy'", "'squared_error'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}}, "machines": {"cd optimiation": {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz", "machine": "cd optimiation", "num_cpu": "12", "os": "Linux 5.8.0-55-generic", "ram": "65698320", "version": 1}}, "tags": {"0.1.0": 616, "0.2.0": 1136, "0.2.1": 1358, "0.3.0": 1887, "0.3.1": 2038, "0.4.0": 2419, "0.5.0": 3334}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}