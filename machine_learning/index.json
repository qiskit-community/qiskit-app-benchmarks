{"project": "qiskit-machine-learning", "project_url": "https://qiskit.org/documentation/machine-learning/", "show_commit_url": "http://github.com/Qiskit/qiskit-machine-learning/commit/", "hash_length": 8, "revision_to_hash": {"616": "3a6a456bd0c78de570ddddd242c9f13ef9ac7abc", "1136": "e5c3c8d50f2337f46a6a5d0dbad05a1e4807b97e", "1358": "ec3cbccca8f8c588d1ac523f4b12dc8c0bcef5b9", "1887": "0385b8ae6155c43a79bdf19f1a0a6d7828f60be7", "2038": "e927a4850d2b4ae83441343c56cbd544d1555cff", "2419": "63ecb3184216f56103f1e76d8facef792810a62f", "3007": "aae0bd472b72783bdd691a51e84aef89a6fb281c", "3032": "3702b74b8c515cdcdf82c5aa81036b652d28a0f7", "3044": "66e0476e9061751d0271df879d7c83a0f05a479f", "3053": "8f76b5ea28040b35acae320306c226519ea2566c", "3065": "6bd0be33cc96e9e4779f2c8ff7257c5ddc8e65d3", "3154": "c8d6eb271cc2a7e869a9200d663aa258de8fb2d4", "3170": "a53abb2b02162d9407849d9be3ff55db57d6b544", "3208": "2629e70c75f59bb7315cdd012dc8ed65898ffaf9", "3243": "670bc12ac7b696acdf4b1ea3e9f4242953a8555d", "3275": "ea94895f607065b2eb24a087c710dfa332debc24", "3284": "941bbea133eaf629f34c7406376e55b78f52821a", "3289": "f354fd502e51321162268bf25a92f698a0c25f79", "3302": "40f99bbe0bd055057ee0939034ec6f18d78f260f", "3307": "af319b7c04ab5e2330ab9e95543cc2e9b24d8ed6", "3312": "3c22367c822796691fe565786583e3b9e199da08", "3331": "c6f4216c6b336aa686e50c28d797257c3e664618", "3335": "85c028c15cc3de7cbf4afb4a3ce6af78d30b7acc", "3338": "892a672a6a6df0801d8176f95a7baa8ffe489498", "3345": "20e0f1bb9a6782728e1613cd0099fc07a5a628db", "3354": "a9ec4a60c038c3513e1fed34f7a30e52272b9a3b", "3361": "4b6191d6141e8dae006207b3173b89035cb8d553", "3365": "c45a510b323a3548ae3b0e72ad0edf527d400961", "3383": "0f83bbd58549021209435d591dc32bbbc43ccb90", "3389": "c4561bbdd759efc2518a2d8aacebb1c7e2361996", "3393": "ff7b90819632ba4c4ca66db5fbd1dfcbf972bece", "3399": "c660b1104be77fb29449a2b96f13867c1a2a8cde", "3459": "aae91726923e01a426c1de90f2876c0ac51253b9", "3485": "089ec0e843abeb026e933ab97a325421a80c9d65", "3487": "2542b764adada975783b65a6f41514774e4347e6", "3526": "4c57b6d0ee229bbb1d8f086bf0825c3b6eaabcad", "3533": "66c3832f6de9a953b66c745251f7f90944d0aae6", "3540": "3e05995cf87ef52c335814f15ba2e4e324fcf720", "3547": "de7ad4f24adb142149a6defa558d4381737e9e9c", "3553": "7d28022d04e1f9cca6ef49d875d1d9bbb11e2e5b", "3569": "a280163c695b032b7c888135124e190042da23b3", "3590": "5ac81df9f4dfe28897a31eca5fef603815fe18a0", "3605": "8c94cbac06108c909bf50c404e2857e0c227009d", "3632": "0aea8c008cdeea5a49c4aea2dd1a68b908226086", "3649": "10f162b018cb1cd05a9d9a5132ef33fe37c6b00c", "3654": "5773e9cbea18c455572228e9e01d16e82e4065fb", "3661": "b6d0c36e3b0f339ba11729ffa48b24ac6f7d5080", "3667": "da8a8e7c41b7fb9167578596e7006111656cfb9c", "3680": "89eac3b39924ebfdcbb2b05a22d70e745e791c09", "3690": "f475df34e26ab0564a399664446a43a746ce06c3", "3725": "9b1c56e3003aa3db0f02808ebd8261c43bd1af41", "3736": "b6e6b1378608338f670361e61859b574627b0b1e", "3738": "5abda6c0fd303453229f9caabcd831de792fdd75", "3765": "30ea03047f1f2f5a4469fea49fbcdd6642c4a714", "3773": "3a869ae3f671e1d180d1844839f409008e74a1f6", "3782": "7050517a0ac7221bbbf3afbe94e5833d37c761e1", "3787": "a8621a121847e53abeb8f0aaa9c4024d5e902678", "3791": "ffe2b6f7339f3f98fd6a6afd84e5c5324db9dbd9", "3799": "55baa9d58879f25ff8d75d28f214b16500fd32e8", "3813": "9596dc47cc9d41c02c46b9b4a57b72d159f8e130", "3816": "2c771ccb78a5a44112b1157f26c9d4f6afc5115e", "3820": "6b3c65a45085e5f7b3258d67ba02cc2bff5786d3", "3822": "405e3be06a3e2a1b20c97b30a59d425ed4ad117d", "3827": "94bc39bb2f3d08546b35f0b20a9a9e38ca17d150", "3831": "3a1f680b5ba9c916e4efaa01968c174779618894", "3845": "12830368e6ad721f12b7b51bf0eca2938533fd43", "3848": "bd378aed709a8f14e37b4b8c96fd68b2ffca4557", "3859": "34ed53590093a70025e88a7958b018ec10df6640", "3868": "b01f4668850cadc245929972238290cbfdd16ee7", "3876": "baceeb23427e925ddb4568c946737ef7eaa9c19d", "3890": "410d212df67f60d6d8eff88e0109bb01de03d9a8", "3898": "10aa219e627f62b8df59d83eceb59fbdc81c8b45", "3904": "8cea2c8ad42930e6ed812cfd13cd17fd0c1b1f22", "3911": "4d41b5b7234b4db94db6c9fa3bbcd8b279779ebc", "3921": "09e6c121307c7af7496a1fe50a3bab3a207561d5", "3930": "090e70ccb47fe4b52f68ac6e3138eddc0f6336fd", "3939": "ace538b4f3593159da486b4496d98400ea7f710f", "3945": "b3ee3e611b60a9990d20860ddd2bec59a78dd989", "3950": "2ef8f8686cb7f7a94e4ff77c3d899ebdfdcb4cfe", "3954": "c0eb6b8dfe8f74e037d76f16e583092de7515547", "3965": "bf3d88c5d14372b55c0704db7b1089f502e3ec81", "3969": "e313cac9573dc051a56f8f3b4f9e847af6d562d0", "3976": "bbc73410635269850e9765f1e4c37c7efde865aa", "3988": "6950608fd06df2af2f68a14e01c3d7672cff8067", "4004": "03bb83c18c852bccfd26620cd564709119dd4549", "4010": "fa1067b09e509c9758671f991ec9a774bcfa325f", "4020": "1b4f00a4427a19da88e2311361dfd8d4ac1a4bc2", "4037": "f32c0126e9a9348e9024d4563fce76c2cc2a787e", "4041": "3f7d0008412f5dacf6cb7ed61f64c0bcfbc8174a"}, "revision_to_date": {"616": 1617272920000, "1136": 1626124407000, "1358": 1629808246000, "1887": 1639585424000, "2038": 1645139709000, "2419": 1651248798000, "3007": 1665500939000, "3032": 1665673993000, "3044": 1665746131000, "3053": 1666003402000, "3065": 1666016466000, "3154": 1666293828000, "3170": 1666629576000, "3208": 1666903793000, "3243": 1667260125000, "3275": 1667394336000, "3284": 1667424822000, "3289": 1667505476000, "3302": 1667570690000, "3307": 1667584727000, "3312": 1667595850000, "3331": 1667939839000, "3335": 1667947182000, "3338": 1667995079000, "3345": 1668089791000, "3354": 1668177108000, "3361": 1668417022000, "3365": 1668440442000, "3383": 1668531701000, "3389": 1668595563000, "3393": 1668628613000, "3399": 1668683912000, "3459": 1669654961000, "3485": 1669917175000, "3487": 1669924739000, "3526": 1670427997000, "3533": 1670489814000, "3540": 1670517606000, "3547": 1670533567000, "3553": 1670632423000, "3569": 1671059227000, "3590": 1672781150000, "3605": 1674146171000, "3632": 1674557451000, "3649": 1675262345000, "3654": 1675709491000, "3661": 1675771775000, "3667": 1675867308000, "3680": 1676394385000, "3690": 1676894743000, "3725": 1677262767000, "3736": 1677790118000, "3738": 1678115251000, "3765": 1679403331000, "3773": 1679411998000, "3782": 1679484379000, "3787": 1679498749000, "3791": 1679528415000, "3799": 1679586911000, "3813": 1679915525000, "3816": 1679928088000, "3820": 1679950044000, "3822": 1679957554000, "3827": 1679961470000, "3831": 1679966576000, "3845": 1680725101000, "3848": 1680783718000, "3859": 1681237661000, "3868": 1681811957000, "3876": 1681858520000, "3890": 1682959170000, "3898": 1683038186000, "3904": 1683053121000, "3911": 1683060290000, "3921": 1683118615000, "3930": 1683188368000, "3939": 1683230178000, "3945": 1683551825000, "3950": 1683619078000, "3954": 1683729639000, "3965": 1683843522000, "3969": 1683900756000, "3976": 1683921659000, "3988": 1684148475000, "4004": 1684397911000, "4010": 1684763561000, "4020": 1685006147000, "4037": 1685350565000, "4041": 1685434167000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz"], "machine": ["cd optimiation"], "num_cpu": ["12"], "os": ["Linux 5.8.0-55-generic"], "ram": ["65698320"], "python": ["3.8"], "torch": [""], "sparse": [""], "branch": ["main"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz", "machine": "cd optimiation", "num_cpu": "12", "os": "Linux 5.8.0-55-generic", "ram": "65698320", "python": "3.8", "torch": "", "sparse": "", "branch": "main"}], "benchmarks": {"circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_predict_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def time_predict_circuit_qnn_classifier(self, _, __):\n        \"\"\"Time predicting with CircuitQNN classifier.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_predict_circuit_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def time_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Time scoring CircuitQNN classifier on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.time_score_circuit_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_accuracy_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_accuracy_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the overall accuracy of the classification results.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_accuracy_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_f1_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_f1_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the f1 score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return f1_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_f1_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_precision_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_precision_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the precision score.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return precision_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_precision_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_recall_score_circuit_qnn_classifier": {"code": "class CircuitQnnClassifierBenchmarks:\n    def track_recall_score_circuit_qnn_classifier(self, _, __):\n        \"\"\"Tracks the recall score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return recall_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"circuit_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_qnn_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_qnn_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"circuit_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "circuit_qnn_classifier_benchmark.CircuitQnnClassifierBenchmarks.track_recall_score_circuit_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "circuit_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "circuit_qnn_classifier_fit_benchmark.CircuitQnnFitClassifierBenchmarks.time_fit_circuit_qnn_classifier": {"code": "class CircuitQnnFitClassifierBenchmarks:\n    def time_fit_circuit_qnn_classifier(self, _, __, ___):\n        \"\"\"Time fitting CircuitQNN classifier to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str, optimizer: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_qnn_classifier_iris(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "circuit_qnn_classifier_fit_benchmark.CircuitQnnFitClassifierBenchmarks.time_fit_circuit_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name", "optimizer"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_predict_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def time_predict_opflow_qnn_classifier(self, _, __):\n        \"\"\"Time predicting with classifier OpflowQNN.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_predict_opflow_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def time_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Time scoring OpflowQNN classifier on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.time_score_opflow_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_accuracy_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_accuracy_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the overall accuracy of the classification results.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_accuracy_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_f1_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_f1_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the f1 score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return f1_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_f1_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_precision_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_precision_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the precision score.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return precision_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_precision_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_recall_score_opflow_qnn_classifier": {"code": "class OpflowQnnClassifierBenchmarks:\n    def track_recall_score_opflow_qnn_classifier(self, _, __):\n        \"\"\"Tracks the recall score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return recall_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"opflow_qnn_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache CircuitQNN fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_opflow_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_opflow_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"opflow_qnn_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_classifier_benchmark.OpflowQnnClassifierBenchmarks.track_recall_score_opflow_qnn_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_classifier_benchmark:73", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "opflow_qnn_classifier_fit_benchmark.OpflowQnnFitClassifierBenchmarks.time_fit_opflow_qnn_classifier": {"code": "class OpflowQnnFitClassifierBenchmarks:\n    def time_fit_opflow_qnn_classifier(self, _, __, ___):\n        \"\"\"Time fitting OpflowQNN classifier to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str, optimizer: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_opflow_classifier_iris(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "opflow_qnn_classifier_fit_benchmark.OpflowQnnFitClassifierBenchmarks.time_fit_opflow_qnn_classifier", "number": 0, "param_names": ["dataset", "backend name", "optimizer"], "params": [["'dataset_synthetic'", "'dataset_iris'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_predict_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def time_predict_opflow_qnn_regressor(self, _, __):\n        \"\"\"Time predicting with OpflowQNN regressor.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_predict_opflow_qnn_regressor", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "1", "warmup_time": -1}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_score_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def time_score_opflow_qnn_regressor(self, _, __):\n        \"\"\"Time scoring OpflowQNN regressor on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.time_score_opflow_qnn_regressor", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "1", "warmup_time": -1}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mae_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def track_mae_opflow_qnn_regressor(self, _, __):\n        \"\"\"Mean absolute error of the model on data.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        mae = mean_absolute_error(y_true=self.test_labels, y_pred=predicts)\n        return mae\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mae_opflow_qnn_regressor", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1"}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mse_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def track_mse_opflow_qnn_regressor(self, _, __):\n        \"\"\"Mean squared error of the model on data.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        mse = mean_squared_error(y_true=self.test_labels, y_pred=predicts)\n        return mse\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_mse_opflow_qnn_regressor", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1"}, "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_score_opflow_qnn_regressor": {"code": "class OpflowQnnRegressorBenchmarks:\n    def track_score_opflow_qnn_regressor(self, _, __):\n        \"\"\"R2 score of the model on data.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(quantum_instance_name=quantum_instance_name)\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name=quantum_instance_name)\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache Opflow fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_REGRESSION:\n                model = self._construct_qnn_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA()\n                )\n            elif dataset == DATASET_CCPP_REGRESSION:\n                model = self._construct_qnn_ccpp(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=100)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "opflow_qnn_regressor_benchmark.OpflowQnnRegressorBenchmarks.track_score_opflow_qnn_regressor", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "opflow_qnn_regressor_benchmark:49", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1"}, "opflow_qnn_regressor_fit_benchmark.OpflowQnnFitRegressorBenchmarks.time_fit_opflow_qnn_regressor": {"code": "class OpflowQnnFitRegressorBenchmarks:\n    def time_fit_opflow_qnn_regressor(self, _, __, ___):\n        \"\"\"Time fitting OpflowQNN regressor to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str, optimizer: str):\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_REGRESSION:\n            self.model = self._construct_qnn_synthetic(\n                quantum_instance_name, self.optimizers[optimizer]\n            )\n        elif dataset == DATASET_CCPP_REGRESSION:\n            self.model = self._construct_qnn_ccpp(quantum_instance_name, self.optimizers[optimizer])\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "opflow_qnn_regressor_fit_benchmark.OpflowQnnFitRegressorBenchmarks.time_fit_opflow_qnn_regressor", "number": 0, "param_names": ["dataset", "backend name", "optimizer"], "params": [["'dataset_synthetic_regression'", "'dataset_ccpp'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "1", "warmup_time": -1}, "vqc_benchmark.VqcBenchmarks.time_predict_vqc_classifier": {"code": "class VqcBenchmarks:\n    def time_predict_vqc_classifier(self, _, __):\n        \"\"\"Time predicting with VQC.\"\"\"\n        self.model.predict(self.train_features)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "vqc_benchmark.VqcBenchmarks.time_predict_vqc_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "vqc_benchmark.VqcBenchmarks.time_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def time_score_vqc_classifier(self, _, __):\n        \"\"\"Time scoring VQC on data.\"\"\"\n        self.model.score(self.train_features, self.train_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "min_run_count": 2, "name": "vqc_benchmark.VqcBenchmarks.time_score_vqc_classifier", "number": 0, "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}, "vqc_benchmark.VqcBenchmarks.track_accuracy_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_accuracy_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the overall accuracy of the classification results.\"\"\"\n        return self.model.score(self.test_features, self.test_labels)\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_accuracy_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_benchmark.VqcBenchmarks.track_f1_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_f1_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the f1 score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return f1_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_f1_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_benchmark.VqcBenchmarks.track_precision_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_precision_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the precision score.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return precision_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_precision_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_benchmark.VqcBenchmarks.track_recall_score_vqc_classifier": {"code": "class VqcBenchmarks:\n    def track_recall_score_vqc_classifier(self, _, __):\n        \"\"\"Tracks the recall score for each class of the classification results.\"\"\"\n        predicts = self.model.predict(self.test_features)\n        return recall_score(y_true=self.test_labels, y_pred=predicts, average=\"micro\")\n\n    def setup(self, dataset: str, quantum_instance_name: str) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n    \n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n        self.test_features = self.datasets[dataset][\"test_features\"]\n        self.test_labels = self.datasets[dataset][\"test_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n        file_name = f\"vqc_{dataset}_{quantum_instance_name}.pickle\"\n        with open(file_name, \"rb\") as file:\n            self.model._fit_result = pickle.load(file)\n\n    def setup_cache(self) -> None:\n        \"\"\"Cache VQC fitted model.\"\"\"\n        for dataset, backend in product(*self.params):\n            train_features = self.datasets[dataset][\"train_features\"]\n            train_labels = self.datasets[dataset][\"train_labels\"]\n    \n            if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n                model = self._construct_vqc_classifier_synthetic(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            elif dataset == DATASET_IRIS_CLASSIFICATION:\n                model = self._construct_vqc_classifier_iris(\n                    quantum_instance_name=backend, optimizer=COBYLA(maxiter=200)\n                )\n            else:\n                raise ValueError(f\"Unsupported dataset: {dataset}\")\n    \n            model.fit(train_features, train_labels)\n    \n            file_name = f\"vqc_{dataset}_{backend}.pickle\"\n            with open(file_name, \"wb\") as file:\n                pickle.dump(model._fit_result, file)", "name": "vqc_benchmark.VqcBenchmarks.track_recall_score_vqc_classifier", "param_names": ["dataset", "backend name"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"]], "setup_cache_key": "vqc_benchmark:70", "timeout": 1200.0, "type": "track", "unit": "unit", "version": "2"}, "vqc_fit_benchmark.VqcFitBenchmarks.time_fit_vqc": {"code": "class VqcFitBenchmarks:\n    def time_fit_vqc(self, _, __, ___, ____):\n        \"\"\"Time fitting VQC to data.\"\"\"\n        self.model.fit(self.train_features, self.train_labels)\n\n    def setup(\n        self, dataset: str, quantum_instance_name: str, optimizer: str, loss_function: str\n    ) -> None:\n        \"\"\"Set up the benchmark.\"\"\"\n        self.train_features = self.datasets[dataset][\"train_features\"]\n        self.train_labels = self.datasets[dataset][\"train_labels\"]\n    \n        if dataset == DATASET_SYNTHETIC_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_synthetic(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n                loss_function=loss_function,\n            )\n        elif dataset == DATASET_IRIS_CLASSIFICATION:\n            self.model = self._construct_vqc_classifier_iris(\n                quantum_instance_name=quantum_instance_name,\n                optimizer=self.optimizers[optimizer],\n                loss_function=loss_function,\n            )\n        else:\n            raise ValueError(f\"Unsupported dataset: {dataset}\")", "min_run_count": 2, "name": "vqc_fit_benchmark.VqcFitBenchmarks.time_fit_vqc", "number": 0, "param_names": ["dataset", "backend name", "optimizer", "loss function"], "params": [["'dataset_synthetic'"], ["'qasm_simulator'", "'statevector_simulator'"], ["'cobyla'", "'nelder-mead'", "'l-bfgs-b'"], ["'cross_entropy'", "'squared_error'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1200.0, "type": "time", "unit": "seconds", "version": "2", "warmup_time": -1}}, "machines": {"cd optimiation": {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz", "machine": "cd optimiation", "num_cpu": "12", "os": "Linux 5.8.0-55-generic", "ram": "65698320", "version": 1}}, "tags": {"0.1.0": 616, "0.2.0": 1136, "0.2.1": 1358, "0.3.0": 1887, "0.3.1": 2038, "0.4.0": 2419, "0.5.0": 3335, "0.6.0": 3820, "0.6.1": 3950}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}